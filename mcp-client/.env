# MCP Client Configuration
# Copy this file to .env and fill in your values

# ============================================================================
# LLM Configuration
# ============================================================================

# Ollama model to use (run 'ollama list' to see available models)
LLM__MODEL_NAME=gpt-oss:20b  # Only model with tool calling support

# Temperature for LLM responses (0.0 = deterministic, 2.0 = very creative)
LLM__TEMPERATURE=0.0

# Timeout for LLM calls in seconds
LLM__TIMEOUT_SECONDS=180  # Increased for final synthesis after multiple tool calls

# Maximum iterations for agent loop (lower = faster, prevents infinite loops)
LLM__MAX_ITERATIONS=20

# ============================================================================
# Ollama Configuration
# ============================================================================

# Ollama server URL
OLLAMA_BASE_URL=http://localhost:11434

# ============================================================================
# Logging Configuration
# ============================================================================

# Log level: TRACE, DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=DEBUG

# ============================================================================
# Database Configuration (Optional - for conversation persistence)
# ============================================================================

# Uncomment these lines to enable PostgreSQL-backed conversation memory

DATABASE__HOST=localhost
DATABASE__PORT=5432
DATABASE__DATABASE=mcp_client
DATABASE__USER=mcp_user
DATABASE__PASSWORD=changeme
DATABASE__POOL_MIN_SIZE=2
DATABASE__POOL_MAX_SIZE=10

# ============================================================================
# Metrics Configuration
# ============================================================================

# Enable Prometheus metrics endpoint
METRICS_ENABLED=true

# Port for Prometheus metrics endpoint (/metrics)
METRICS_PORT=9090

# ============================================================================
# MCP Server Configuration
# ============================================================================
# Note: Server configuration is done in code (client.py) for now.
# Future enhancement: Move to config file or environment variables.
#
# Example servers that can be configured:
# - Weather server: /Users/hamzilla/mcp/weather/weather.py
# - Bitbucket server: /Users/hamzilla/mcp/bitbucket-mcp/main.py
# - Grafana server (future): https://github.com/grafana/mcp-grafana
# - Kubernetes server (future): https://github.com/containers/kubernetes-mcp-server
# - GCP server (future): https://github.com/googleapis/gcloud-mcp
