# MCP Client Configuration
# Copy this file to .env and fill in your values

# ============================================================================
# LLM Configuration
# ============================================================================

# Ollama model to use (run 'ollama list' to see available models)
LLM__MODEL_NAME=gpt-oss:20b  # Only model with tool calling support

# Temperature for LLM responses (0.0 = deterministic, 2.0 = very creative)
LLM__TEMPERATURE=0.0

# Timeout for LLM calls in seconds
LLM__TIMEOUT_SECONDS=180  # Increased for final synthesis after multiple tool calls

# Maximum iterations for agent loop (lower = faster, prevents infinite loops)
LLM__MAX_ITERATIONS=20

# ============================================================================
# Ollama Configuration
# ============================================================================

# Ollama server URL
OLLAMA_BASE_URL=http://localhost:11434

# ============================================================================
# Logging Configuration
# ============================================================================

# Log level: TRACE, DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=DEBUG

# ============================================================================
# Database Configuration (Optional - for conversation persistence)
# ============================================================================

# Uncomment these lines to enable PostgreSQL-backed conversation memory

DATABASE__HOST=localhost
DATABASE__PORT=5432
DATABASE__DATABASE=mcp_client
DATABASE__USER=mcp_user
DATABASE__PASSWORD=changeme
DATABASE__POOL_MIN_SIZE=2
DATABASE__POOL_MAX_SIZE=10

# ============================================================================
# Metrics Configuration
# ============================================================================

# Enable Prometheus metrics endpoint
METRICS_ENABLED=true

# Port for Prometheus metrics endpoint (/metrics)
METRICS_PORT=9090

# ============================================================================
# MCP Server Configuration
# ============================================================================
# Server configuration is now done in servers.yaml
# See servers.yaml.example for examples

# ============================================================================
# Remote MCP Server Configuration (SSE Transport)
# ============================================================================

# Environment variables referenced in servers.yaml
# Set here for local dev, or use K8s secrets in production

# Example: Weather Service
# WEATHER_SERVICE_URL=https://weather-mcp.prod.svc.cluster.local/sse
# WEATHER_AUTH_TOKEN=your_token_here

# Example: Kubernetes Service
# K8S_MCP_URL=https://k8s-mcp-service:8080/sse
# K8S_SERVICE_TOKEN=your_k8s_service_account_token
